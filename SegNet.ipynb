{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMAQ1WZKf3ROaQxZdzeFKxY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKmeT6p8NHkp",
        "outputId": "d1019a27-1902-4e15-9ebc-81e094b366b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/carlolepelaars/camvid/versions/2\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"carlolepelaars/camvid\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import random"
      ],
      "metadata": {
        "id": "z33kqaB6N3N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpv1ikZ_SVUv",
        "outputId": "cc8eff25-126c-4910-f0a8-f1859163a91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CamVidDataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "\n",
        "        image_dir = os.path.join(root_dir, split)\n",
        "        mask_dir = os.path.join(root_dir, f'{split}_labels')\n",
        "\n",
        "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.png')])\n",
        "        self.mask_files = sorted([f for f in os.listdir(mask_dir) if f.endswith('_L.png')])\n",
        "\n",
        "        class_dict_path = os.path.join(root_dir, 'class_dict.csv')\n",
        "        self.class_df = pd.read_csv(class_dict_path)\n",
        "        self.name_to_rgb = {row['name']: (row['r'], row['g'], row['b']) for index, row in self.class_df.iterrows()}\n",
        "        self.rgb_to_id = {v: index for index, v in enumerate(self.name_to_rgb.values())}\n",
        "        self.id_to_class = {v: k for k, v in enumerate(self.name_to_rgb.keys())}\n",
        "        self.class_to_id = {k: v for v, k in self.id_to_class.items()}\n",
        "        self.num_classes = len(self.class_to_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        mask_name = img_name.replace('.png', '_L.png')\n",
        "\n",
        "        img_path = os.path.join(self.root_dir, self.split, img_name)\n",
        "        mask_path = os.path.join(self.root_dir, f'{self.split}_labels', mask_name)\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        mask = Image.open(mask_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        mask_np = np.array(mask).astype(np.uint8)\n",
        "        mask_np = mask_np.transpose(1, 2, 0)\n",
        "\n",
        "        semantic_mask = np.zeros(mask_np.shape[:2], dtype=np.int64)\n",
        "\n",
        "        for rgb_tuple, class_id in self.rgb_to_id.items():\n",
        "            rgb_array = np.array(rgb_tuple, dtype=np.uint8)\n",
        "            try:\n",
        "                semantic_mask[(mask_np == rgb_array).all(axis=2)] = class_id\n",
        "            except ValueError as e:\n",
        "                raise e\n",
        "\n",
        "        mask = torch.from_numpy(semantic_mask)\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "KzjRzsBhN7ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 256\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "pslPxfs1N7eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/root/.cache/kagglehub/datasets/carlolepelaars/camvid/versions/2/CamVid'\n",
        "train_dataset = CamVidDataset(root_dir, split='train', transform=transform)\n",
        "val_dataset = CamVidDataset(root_dir, split='val', transform=transform)\n",
        "test_dataset = CamVidDataset(root_dir, split='test', transform=transform)"
      ],
      "metadata": {
        "id": "oZtt_EcJN7bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "LkwiBhFFN7ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegNetEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        x, indices = self.pool(x)\n",
        "        return x, indices"
      ],
      "metadata": {
        "id": "AizY46eROFDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegNetDecoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x, indices, output_size):\n",
        "        x = self.unpool(x, indices, output_size=output_size)\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        return x"
      ],
      "metadata": {
        "id": "z2y1sl0qO-6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegNet(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder1 = SegNetEncoder(in_channels, 64)\n",
        "        self.encoder2 = SegNetEncoder(64, 128)\n",
        "        self.encoder3 = SegNetEncoder(128, 256)\n",
        "        self.encoder4 = SegNetEncoder(256, 512)\n",
        "\n",
        "        self.decoder4 = SegNetDecoder(512, 256)\n",
        "        self.decoder3 = SegNetDecoder(256, 128)\n",
        "        self.decoder2 = SegNetDecoder(128, 64)\n",
        "        self.decoder1 = SegNetDecoder(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1, indices1 = self.encoder1(x)\n",
        "        enc2, indices2 = self.encoder2(enc1)\n",
        "        enc3, indices3 = self.encoder3(enc2)\n",
        "        enc4, indices4 = self.encoder4(enc3)\n",
        "\n",
        "        dec4 = self.decoder4(enc4, indices4, enc3.size())\n",
        "        dec3 = self.decoder3(dec4, indices3, enc2.size())\n",
        "        dec2 = self.decoder2(dec3, indices2, enc1.size())\n",
        "        dec1 = self.decoder1(dec2, indices1, x.size())\n",
        "\n",
        "        return dec1\n"
      ],
      "metadata": {
        "id": "k6vhWzPaO-3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 평가 함수"
      ],
      "metadata": {
        "id": "RLRMHcDdPoqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1_metrics(pred_mask, true_mask, threshold=0.5):\n",
        "    if isinstance(pred_mask, torch.Tensor):\n",
        "        pred_mask = pred_mask.detach().cpu().numpy()\n",
        "    if isinstance(true_mask, torch.Tensor):\n",
        "        true_mask = true_mask.detach().cpu().numpy()\n",
        "\n",
        "    pred_flat = (pred_mask > threshold).astype(int).flatten()\n",
        "    true_flat = (true_mask > threshold).astype(int).flatten()\n",
        "\n",
        "    precision = precision_score(true_flat, pred_flat, zero_division=0)\n",
        "    recall = recall_score(true_flat, pred_flat, zero_division=0)\n",
        "    f1 = f1_score(true_flat, pred_flat, zero_division=0)\n",
        "\n",
        "    return precision, recall, f1"
      ],
      "metadata": {
        "id": "MgmGY6LYPrDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_pixel_accuracy(pred_mask, true_mask):\n",
        "    correct_pixels = (pred_mask == true_mask).sum().float()\n",
        "    total_pixels = torch.numel(pred_mask)\n",
        "    pixel_accuracy = correct_pixels / total_pixels\n",
        "    return pixel_accuracy\n"
      ],
      "metadata": {
        "id": "10klnqReY8pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#시각화"
      ],
      "metadata": {
        "id": "g0h2j5yoPsQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_segmentation(images, true_masks, pred_masks, id_to_class):\n",
        "    batch_size = images.size(0)\n",
        "    fig, axes = plt.subplots(batch_size, 3, figsize=(10, 5 * batch_size))\n",
        "    for i in range(batch_size):\n",
        "        img = images[i].permute(1, 2, 0).numpy()\n",
        "        true_mask = true_masks[i].numpy()\n",
        "        pred_mask = pred_masks[i].numpy()\n",
        "\n",
        "        axes[i, 0].imshow(img)\n",
        "        axes[i, 0].set_title('Image')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        axes[i, 1].imshow(decode_segmap(true_mask, id_to_class))\n",
        "        axes[i, 1].set_title('True Mask')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        axes[i, 2].imshow(decode_segmap(pred_mask, id_to_class))\n",
        "        axes[i, 2].set_title('Predicted Mask')\n",
        "        axes[i, 2].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def decode_segmap(mask, id_to_class):\n",
        "    n_classes = len(id_to_class)\n",
        "    label_colors = np.random.randint(0, 255, size=(n_classes, 3), dtype=np.uint8)\n",
        "    r = np.zeros_like(mask).astype(np.uint8)\n",
        "    g = np.zeros_like(mask).astype(np.uint8)\n",
        "    b = np.zeros_like(mask).astype(np.uint8)\n",
        "    for l in range(0, n_classes):\n",
        "        idx = mask == l\n",
        "        r[idx] = label_colors[l, 0]\n",
        "        g[idx] = label_colors[l, 1]\n",
        "        b[idx] = label_colors[l, 2]\n",
        "    rgb = np.stack([r, g, b], axis=2)\n",
        "    return rgb"
      ],
      "metadata": {
        "id": "1d2cpLK5PrkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "uCfgk0NUOFBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels = 3\n",
        "num_classes = train_dataset.num_classes\n",
        "segnet_model = SegNet(in_channels, num_classes).to(device)"
      ],
      "metadata": {
        "id": "pdyYo_AePYFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(segnet_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "RC3bo9xRPYDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 101"
      ],
      "metadata": {
        "id": "a-yASlM4PYAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#체크포인트 로드"
      ],
      "metadata": {
        "id": "QG6DgmF2qUqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(model, optimizer, checkpoint_path):\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        print(f\"✅ Loaded checkpoint from epoch {start_epoch}\")\n",
        "        return start_epoch\n",
        "    else:\n",
        "        print(\"⚠️ Checkpoint not found. Starting from scratch.\")\n",
        "        return 0"
      ],
      "metadata": {
        "id": "K1HbCK7bqWPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/Dataset/SegNet_CheckPoint'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "vNO-5Tldq9sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = '/content/drive/MyDrive/Dataset/SegNet_CheckPoint/checkpoint_epoch_100.pth'\n",
        "start_epoch = load_checkpoint(segnet_model, optimizer, checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gFi1BIbqlGS",
        "outputId": "540d4822-1c7e-4b48-8f67-3b9fe3c1b6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded checkpoint from epoch 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "train_pixel_accuracies = []\n",
        "val_pixel_accuracies = []\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    segnet_model.train()\n",
        "    train_loss = 0.0\n",
        "    train_accuracy = 0.0\n",
        "    train_progress = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} (Train)')\n",
        "    first_train_batch = True\n",
        "\n",
        "    for images, masks in train_progress:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = segnet_model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_progress.set_postfix(loss=loss.item())\n",
        "\n",
        "        _, predicted_train = torch.max(outputs.data, 1)\n",
        "        pixel_accuracy = calculate_pixel_accuracy(predicted_train, masks)\n",
        "        train_accuracy += pixel_accuracy.item()\n",
        "\n",
        "        if first_train_batch:\n",
        "            visualize_segmentation(images.cpu(), masks.cpu(), predicted_train.cpu(), train_dataset.id_to_class)\n",
        "            first_train_batch = False\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    avg_train_accuracy = train_accuracy / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    train_pixel_accuracies.append(avg_train_accuracy)\n",
        "\n",
        "    segnet_model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_accuracy = 0.0\n",
        "    val_progress = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} (Validation)')\n",
        "    first_val_batch = True\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images_val, masks_val in val_progress:\n",
        "            images_val = images_val.to(device)\n",
        "            masks_val = masks_val.to(device)\n",
        "            outputs_val = segnet_model(images_val)\n",
        "            loss_val = criterion(outputs_val, masks_val)\n",
        "            val_loss += loss_val.item()\n",
        "\n",
        "            _, predicted_val = torch.max(outputs_val.data, 1)\n",
        "            pixel_accuracy = calculate_pixel_accuracy(predicted_val, masks_val)\n",
        "            val_accuracy += pixel_accuracy.item()\n",
        "\n",
        "            val_progress.set_postfix(loss=loss_val.item())\n",
        "\n",
        "            if first_val_batch:\n",
        "                first_val_batch = False\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    avg_val_accuracy = val_accuracy / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_pixel_accuracies.append(avg_val_accuracy)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Train Pixel Accuracy: {train_pixel_accuracies[-1]:.4f}, '\n",
        "          f'Validation Loss: {val_losses[-1]:.4f}, Validation Pixel Accuracy: {val_pixel_accuracies[-1]:.4f}')\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': segnet_model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_losses[-1],\n",
        "            'val_loss': val_losses[-1],\n",
        "        }, checkpoint_path)\n",
        "        print(f'Saved checkpoint: {checkpoint_path}')"
      ],
      "metadata": {
        "id": "Ink2XqPaOE-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 평가"
      ],
      "metadata": {
        "id": "FzFH8zP6Pxog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = '/content/drive/MyDrive/Dataset/SegNet_CheckPoint/checkpoint_epoch_100.pth'\n",
        "\n",
        "checkpoint = torch.load(checkpoint_path)"
      ],
      "metadata": {
        "id": "Wxsc6ktTYcEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segnet_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "start_epoch = checkpoint['epoch']\n",
        "train_loss = checkpoint['train_loss']\n",
        "val_loss = checkpoint['val_loss']\n",
        "\n",
        "print(f\"Checkpoint loaded. Starting from epoch {start_epoch}.\")\n",
        "print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbHWhhNVYa4o",
        "outputId": "486993b3-e8c3-421a-dcd6-0cfbd370c588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded. Starting from epoch 100.\n",
            "Train Loss: 0.2630, Validation Loss: 0.2917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segnet_model.eval()\n",
        "segnet_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X17GMppHPyfe",
        "outputId": "046a8d9a-bf23-4037-e108-1421ed86c5ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SegNet(\n",
              "  (encoder1): SegNetEncoder(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (encoder2): SegNetEncoder(\n",
              "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (encoder3): SegNetEncoder(\n",
              "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (encoder4): SegNetEncoder(\n",
              "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (decoder4): SegNetDecoder(\n",
              "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
              "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (decoder3): SegNetDecoder(\n",
              "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
              "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (decoder2): SegNetDecoder(\n",
              "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
              "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              "  (decoder1): SegNetDecoder(\n",
              "    (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
              "    (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu1): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu2): ReLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_segmentation_result(image, true_mask, predicted_mask):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
        "    plt.title(\"Original Image\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(true_mask.cpu().numpy(), cmap='gray')\n",
        "    plt.title(\"True Mask\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(predicted_mask.cpu().numpy(), cmap='gray')\n",
        "    plt.title(\"Predicted Mask\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aGmd_8ghpUKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "test_data = list(test_loader)\n",
        "random_samples = random.sample(test_data, 5)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (image, label) in enumerate(random_samples):\n",
        "        image, label = image.to(device), label.to(device)\n",
        "\n",
        "        outputs = segnet_model(image)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        precision, recall, f1 = calculate_f1_metrics(predicted[0], label[0])\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        show_segmentation_result(image[0], label[0], predicted[0])\n",
        "\n",
        "print(f\"Test Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Test Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Test F1 Score: {np.mean(f1_scores):.4f}\")"
      ],
      "metadata": {
        "id": "v0VPpBuWpX2x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}